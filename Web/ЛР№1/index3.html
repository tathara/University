<!DOCTYPE html>
<html lang="ru">

<head>
    <link rel="stylesheet" href="assets/css/style.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" charset="UTF-8">
    <title>В поисках свежести</title>
</head>

<body>
    <header>
        <section class="header__inner">
            <a href="index2.html"><img class="nav__button" src="assets/images/reversed__arrow.jpg"
                    alt="Перейти на предыдущую страницу"></a>
            <nav>
                <a class="nav__link" href="https://www.youtube.com/watch?v=8ybW48rKBME&ab_channel=xyzmusic">Главная</a>
                <a class="nav__link" href="https://www.youtube.com/watch?v=FyPBWRp84jg">Статьи</a>
                <a class="nav__link" href="https://www.youtube.com/watch?v=xVgY929D5P8">Контакты</a>
                <a class="nav__link" href="https://www.youtube.com/watch?v=KTfyGVI9Yxc">О нас</a>
                <a href="index4.html"><img class="nav__button" src="assets/images/arrow.jpg"
                        alt="Перейти на следующую страницу"></a>
            </nav>
        </section>
    </header>


    <main>
        <section class="content">
            <h2 class="text__subtitle">Добываем картинки</h2>

            <p>В интернете множество сайтов, многие из них что-то регулярно публикуют, в том числе картинки. Чтобы люди
                увидели всё это в поиске Картинок, робот должен дойти до сайта и скачать контент. Обычно поиск так и
                работает: мы относительно быстро обходим известные нам сайты и получаем новые картинки. Но когда речь
                идёт о контенте, который вдруг становится актуальным прямо сейчас, эта модель не справляется. Потому что
                интернет огромный, невозможно «прямо сейчас» скачать HTML-документы всех сайтов в мире и быстро всё это
                переварить. По крайней мере никто в мире такую задачу ещё не решил.</p>

            <p>Кто-то может представить себе решение проблемы таким образом: отслеживать всплески запросов и в первую
                очередь обрабатывать только те источники, которые как-то соответствуют запросам. Но это хорошо звучит
                только на бумаге. Во-первых, чтобы проверить соответствие чего-то чему-то, нужно уже иметь на руках
                контент. Во-вторых, если мы начинаем что-то делать после пика запросов, то мы уже опоздали. Как бы дико
                это ни звучало, нужно находить свежий контент до того, как в нём возникла потребность. Но как
                предсказать неожиданное?</p>

            <p>Правильный ответ: никак. Мы ничего не знаем о графике извержений вулканов. Но мы знаем, на каких сайтах
                обычно появляется свежий и полезный контент. С этой стороны мы и пошли. Мы стали применять
                машиннообученную формулу, которая приоритизирует обход нашего робота в зависимости от качества и
                актуальности контента. Да простят нас сеошники: в детали тут углубляться не будем. Задача робота — как
                можно быстрее доставить до нас HTML-документы. Только после этого мы можем взглянуть на их начинку и
                найти там новые тексты, ссылки на картинки и т. п.</p>

            <p>Ссылки на картинки — это хорошо, но пока что не особо полезно для поиска. Их в первую очередь нужно
                скачать к нам. Но новых ссылок на картинки опять же слишком много, чтобы скачать их мгновенно. И
                проблема тут не только в наших ресурсах: владельцы сайтов тоже не хотели бы, чтобы Яндекс их случайно
                заддосил. Поэтому мы используем машинное обучение для приоритизации скачивания картинок. Факторы разные,
                их много, всё объяснять не будем, но для примера можем сказать, что частота, с которой картинка
                появляется на разных ресурсах, тоже влияет на приоритет.</p>

            <p>Теперь у нас есть список ссылок на картинки. Дальше мы их скачиваем к себе. При этом используем
                собственный сервис Logbroker. Эта штука выступает в качестве транспортной шины, успешно переживающей
                огромные объёмы трафика. Несколько лет назад наш коллега Алексей Озерицкий уже <a
                    href="https://habr.com/ru/companies/yandex/articles/239823/">рассказывал</a> об этой технологии на
                Хабре.</p>

            <p>На этом первый этап логически завершился. Мы определились с источниками и успешно добыли
                какие-то картинки. Осталось совсем чуть-чуть: научиться с ними работать.</p>
        </section>
    </main>

    <footer>
        <p>© Яндекс, help@yandex.ru, Хохрякова, 10</p>
    </footer>
</body>

</html>